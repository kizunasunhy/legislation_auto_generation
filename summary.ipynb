{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3728e4-d6ef-4eae-9c53-e21bd6ad98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "model_checkpoint = \"t5-small\"\n",
    "model_checkpoint = 'facebook/bart-base'\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "#raw_datasets = load_dataset(\"./xsum.py\")\n",
    "metric = load_metric(\"./rouge1.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f398c71c-57a6-4dfc-9c5a-d9294693e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\"\n",
    "    \n",
    "max_input_length = 256\n",
    "max_target_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d9a0077-2026-447a-884f-b287c0f8c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#load npy files\n",
    "vt = ['train_src', 'val_src', 'train_tar', 'val_tar']\n",
    "for name in vt:\n",
    "    str1 = name.split('_')[0]\n",
    "    str2 = name.split('_')[1]\n",
    "    str3 = str1+'_'+str2[:2]\n",
    "    exec('''{} = np.load('{}.npy', allow_pickle=True)'''.format(name, str3))\n",
    "train_tar_dict = {'0':[], '1':[], '2':[]}\n",
    "val_tar_dict = {'0':[], '1':[], '2':[]}\n",
    "train_src_dict = {'0':[], '1':[]}\n",
    "val_src_dict = {'0':[], '1':[]}\n",
    "for i in range(len(train_tar)):\n",
    "    train_tar_dict['0'].append(train_tar[i][0])\n",
    "    train_tar_dict['1'].append(train_tar[i][1])\n",
    "    train_tar_dict['2'].append(train_tar[i][2])\n",
    "    train_src_dict['0'].append(train_src[i][0])\n",
    "    train_src_dict['1'].append(train_src[i][1])\n",
    "for i in range(len(val_tar)):\n",
    "    val_tar_dict['0'].append(val_tar[i][0])\n",
    "    val_tar_dict['1'].append(val_tar[i][1])\n",
    "    val_tar_dict['2'].append(val_tar[i][2])\n",
    "    val_src_dict['0'].append(val_src[i][0])\n",
    "    val_src_dict['1'].append(val_src[i][1])\n",
    "train_src = train_src.tolist()\n",
    "val_src = val_src.tolist()\n",
    "\n",
    "#---------------------DEFINE LABEL-------------------------\n",
    "label_list = ['O', 'B-substitute', 'I-substitute', 'B-before-insertions', 'I-before-insertions', 'B-after-insertions', \n",
    "              'I-after-insertions', 'B-revocation', 'I-revocation']\n",
    "label_dict = {}\n",
    "label_dict_rev = {}\n",
    "for i in range(len(label_list)):\n",
    "    label_dict[label_list[i]] = i\n",
    "    label_dict_rev[i] = label_list[i]\n",
    "short_label_list = ['O', 'substitute', 'before-insertions', 'after-insertions', 'revocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf987a1b-3956-4294-8701-daf853b33e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 29, 51, 51)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_src_dict['0'][2]), len(train_src_dict['1'][2]), len(train_tar_dict['1'][2]), len(train_tar_dict['2'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52123eaa-b97c-47b9-9ee5-98f51a0703d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_instruction</th>\n",
       "      <th>target_old_content</th>\n",
       "      <th>target_new_content</th>\n",
       "      <th>label</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In subsections (1) and (2)(b) , for “Authority” substitute “regulators”.</td>\n",
       "      <td>comply with any requirements specified in rules made by the Authority.</td>\n",
       "      <td>comply with any requirements specified in rules made by the regulators .</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-substitute]</td>\n",
       "      <td>[10, 11, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In subsections (1) and (2)(b) , for “Authority” substitute “regulators”.</td>\n",
       "      <td>At least once a year , the scheme manager must make a report to the Authority on the discharge of its functions.</td>\n",
       "      <td>At least once a year , the scheme manager must make a report to the regulators on the discharge of its functions.</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-substitute, O, O, O, O, O, O]</td>\n",
       "      <td>[10, 22, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In subsections (1) and (2)(b) , for “Authority” substitute “regulators”.</td>\n",
       "      <td>comply with any requirements specified in rules made by the regulators .</td>\n",
       "      <td>comply with any requirements specified in rules made by the regulators .</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[10, 12, 22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In subsections (1) and (2)(b) , for “Authority” substitute “regulators”.</td>\n",
       "      <td>At least once a year , the scheme manager must make a report to the regulators on the discharge of its functions.</td>\n",
       "      <td>At least once a year , the scheme manager must make a report to the regulators on the discharge of its functions.</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[10, 22, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In section 322 (rules applicable to former underwriting members) , in subsection (1) , for “The Authority” substitute “The PRA” ,</td>\n",
       "      <td>The Authority may make rules imposing such requirements on persons to whom the rules apply as appear to it to be appropriate for protecting policyholders against the risk that those persons may not be able to meet their liabilities.</td>\n",
       "      <td>The PRA may make rules imposing such requirements on persons to whom the rules apply as appear to it to be appropriate for protecting policyholders against the risk that those persons may not be able to meet their liabilities.</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-substitute, I-substitute, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[21, 39, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('1.csv', converters={'label': eval})\n",
    "df = df.drop(df[df['target_new_content']=='0'].index)\n",
    "df = df.reset_index(drop=True)\n",
    "df_final = pd.DataFrame(data=None, columns=df.columns)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(df.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3904f2-abc6-4376-9dc9-111bad7da7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11853/11853 [00:28<00:00, 418.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9717 9717\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#--------------------------PREPROCESS DF DATA-------------------\n",
    "def read_data(df, df_final):\n",
    "    src_lists = []\n",
    "    tar_lists = []\n",
    "    type_lists = []\n",
    "    set_type = {'substitute', 'insert', 'omit'}\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        sr = []\n",
    "        src = df.loc[i, 'source_instruction'].split(' ')\n",
    "        tar = df.loc[i, 'target_old_content'].split(' ')\n",
    "        tar_new = df.loc[i, 'target_new_content'].split(' ')\n",
    "        masked_tar = []\n",
    "        \n",
    "        src = [s.strip() for s in src]\n",
    "        tar = [t.strip() for t in tar]\n",
    "        tar_new = [t.strip() for t in tar_new]\n",
    "        length_src = len(src)\n",
    "        length_tar = len(tar)\n",
    "        length_tar_new = len(tar_new)\n",
    "        \n",
    "        label = df.loc[i, 'label']\n",
    "        if set(label) == set('O') or len(src+tar)!=len(label):\n",
    "            continue\n",
    "        if 'the definition of' in df.loc[i, 'source_instruction']:\n",
    "            continue\n",
    "        #删除substitute或者insert或者omit后没有内容的\n",
    "        if src[-1] in set_type:\n",
    "            continue\n",
    "        if 'B-revocation' in label:\n",
    "            continue\n",
    "        '''\n",
    "        flag = 0\n",
    "        for j in range(length_src):\n",
    "            if flag == 1:\n",
    "                sr.append(src[j]) \n",
    "            if src[j] in set_type:\n",
    "                sr.append(src[j]) \n",
    "                sr.append('<type>')\n",
    "                flag = 1\n",
    "        '''\n",
    "        \n",
    "        label_list = [0]*len(src) + [label_dict.get(j, -100) for j in label[len(src):]]\n",
    "        type_list = [0]*len(src) + [0 if j.split('-')[-1]=='substitute' or\n",
    "                                          j.split('-')[-1]=='revocation' else 1 for j in label[len(src):]] \n",
    "        flag = 0\n",
    "        for j in range(length_src):\n",
    "            if flag == 1:\n",
    "                type_list[j] = 1\n",
    "            if src[j] in set_type:\n",
    "                flag = 1\n",
    "                type_list[j] = 1\n",
    "            sr.append(src[j]) \n",
    "           \n",
    "        for j in range(length_tar):\n",
    "            if label[len(src):][j] == 'O' or label[len(src):][j] == 'I-revocation' or label[len(src):][j] == 'I-before-insertions':\n",
    "                masked_tar.append(tar[j])\n",
    "            if label[len(src):][j] == 'B-substitute' or label[len(src):][j] == 'B-revocation':\n",
    "                masked_tar.append('<change>')\n",
    "            if label[len(src):][j] == 'I-substitute':\n",
    "                continue\n",
    "            if label[len(src):][j] == 'B-before-insertions':\n",
    "                masked_tar.append('<change>')\n",
    "                masked_tar.append(tar[j])\n",
    "            if j == len(tar)-1 and label[len(src):][j].split('-')[-1] == 'insertions':\n",
    "                masked_tar.append(tar[j])\n",
    "                masked_tar.append('<change>')\n",
    "            if j != len(tar)-1:\n",
    "                if label[len(src):][j] == 'B-after-insertions' and label[len(src):][j+1] == 'O':\n",
    "                    masked_tar.append(tar[j])\n",
    "                    masked_tar.append('<change>')\n",
    "                elif label[len(src):][j] == 'I-after-insertions' and label[len(src):][j+1] == 'O':\n",
    "                    masked_tar.append(tar[j])\n",
    "                    masked_tar.append('<change>')\n",
    "                elif label[len(src):][j].split('-')[-1] == 'insertions' and label[len(src):][j+1] != 'O':\n",
    "                    masked_tar.append(tar[j])\n",
    "        \n",
    "        df_final = df_final.append(df.loc[i], ignore_index=True)\n",
    "        src_lists.append([sr, tar])\n",
    "        tar_lists.append([tar_new, type_list, label_list]) \n",
    "    return src_lists, tar_lists, df_final\n",
    "src_lists, tar_lists, df_final = read_data(df, df_final)\n",
    "df_final.to_csv('111.csv', index=False)\n",
    "print(len(src_lists), len(tar_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e19ec2ae-f1b3-4d12-81fd-06a371a4cd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['In', 'subsections', '(1)', 'and', '(2)(b)', ',', 'for', '“Authority”', 'substitute', '“regulators”.'], ['comply', 'with', 'any', 'requirements', 'specified', 'in', 'rules', 'made', 'by', 'the', 'Authority.']]\n",
      "[['comply', 'with', 'any', 'requirements', 'specified', 'in', 'rules', 'made', 'by', 'the', 'regulators', '.'], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "21 21\n",
      "---------------------------\n",
      "[['In', 'subsections', '(1)', 'and', '(2)(b)', ',', 'for', '“Authority”', 'substitute', '“regulators”.'], ['At', 'least', 'once', 'a', 'year', ',', 'the', 'scheme', 'manager', 'must', 'make', 'a', 'report', 'to', 'the', 'Authority', 'on', 'the', 'discharge', 'of', 'its', 'functions.']]\n",
      "[['At', 'least', 'once', 'a', 'year', ',', 'the', 'scheme', 'manager', 'must', 'make', 'a', 'report', 'to', 'the', 'regulators', 'on', 'the', 'discharge', 'of', 'its', 'functions.'], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]]\n",
      "32 32\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    #if 'omit' in src_lists[i][0]:\n",
    "    print(src_lists[i])\n",
    "    print(tar_lists[i])\n",
    "    print(len(src_lists[i][0]+src_lists[i][1]), len(tar_lists[i][1]))\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9b7a0fa-1d9e-4c69-bccb-0471dc81633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "['Ġin', 'Ġrules', 'Ġmade', 'Ġby', 'Ġthe', 'ĠAuthority', '.']\n",
      "[0, 13, 44, 48, 627, 4305, 17, 46, 10268, 44, 48, 627, 5904, 17, 46, 4, 2, 2, 11, 1492, 156, 30, 5, 4305, 4, 2]\n",
      "[None, 0, 1, 1, 1, 2, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, None, None, 6, 7, 8, 9, 10, 11, 11, None]\n",
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, -100]\n",
      "[-100, 0, 0, -100, -100, 0, -100, -100, 0, 0, -100, -100, 0, -100, -100, -100, -100, -100, 0, 0, 0, 0, 0, 0, -100, -100]\n",
      "{0: 1, 1: 2, 2: 5, 3: 8, 4: 9, 5: 12, 6: 18, 7: 19, 8: 20, 9: 21, 10: 22, 11: 23}\n"
     ]
    }
   ],
   "source": [
    "str1 = 'for “the Authority” substitute “the regulators”.'\n",
    "str2 = 'in rules made by the Authority.'\n",
    "list1 = ['\"', 'f', 'motherfucker', 'fuck ', 'you', 'gfhh', 'fdg']\n",
    "list1 = str1.split(' ')\n",
    "list2 = str2.split(' ')\n",
    "#list1 = [a.strip() for a in list1]\n",
    "print(len(list1), len(list2))\n",
    "tokenized_example = tokenizer(\n",
    "                    list1,\n",
    "                    list2, \n",
    "                    max_length=512,\n",
    "                    truncation=\"only_second\",\n",
    "                    is_split_into_words=True,\n",
    "                    return_offsets_mapping=True,\n",
    "                    padding=True,\n",
    "                    )\n",
    "print(tokenizer.tokenize(' '.join(list2)))\n",
    "print(tokenized_example[\"input_ids\"])\n",
    "om = tokenized_example[\"offset_mapping\"]\n",
    "#print(om)\n",
    "label = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-substitute', 'I-substitute'] \n",
    "doc_labels = [label_dict[i] for i in label]\n",
    "doc_enc_labels = np.ones(len(om),dtype=int) * -100\n",
    "#print(doc_enc_labels)\n",
    "arr_offset = np.array(om)\n",
    "#print(arr_offset)\n",
    "l = len(doc_enc_labels[(arr_offset[:,0] == 1)])\n",
    "#print(l)\n",
    "#doc_enc_labels[(arr_offset[:,0] == 1)] = doc_labels[:l]\n",
    "word_ids = tokenized_example.word_ids(0)\n",
    "length = len(list1)\n",
    "cnt = 0\n",
    "for i, ids in enumerate(word_ids):\n",
    "    if word_ids[i] is None:\n",
    "        cnt += 1\n",
    "        continue\n",
    "    if cnt == 3:\n",
    "        word_ids[i] += length \n",
    "print(word_ids)\n",
    "res = [-100 if j is None else doc_labels[j] for j in word_ids]\n",
    "print(res)\n",
    "res=[]\n",
    "ress = ''\n",
    "for j in word_ids:\n",
    "    if j is None or j==ress:\n",
    "        res.append(-100)\n",
    "        continue\n",
    "    res.append(doc_labels[j])\n",
    "    ress = j \n",
    "print(res)\n",
    "word_idx_dict = {}\n",
    "for index, word_idx in enumerate(word_ids):\n",
    "    if word_idx is None or word_idx in word_idx_dict:\n",
    "        continue\n",
    "    word_idx_dict[word_idx] = index\n",
    "print(word_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885d6174-dfa7-4e6b-8408-a679bda38598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "train_src, val_src, train_tar, val_tar = train_test_split(src_lists, tar_lists, test_size=.2)\n",
    "#save npy files\n",
    "vt = ['train_src', 'val_src', 'train_tar', 'val_tar']\n",
    "for name in vt:\n",
    "    str1 = name.split('_')[0]\n",
    "    str2 = name.split('_')[1]\n",
    "    str3 = str1+'_'+str2[:2]\n",
    "    exec('''{} = np.array({})'''.format(str3, name))\n",
    "    exec('''np.save('{}.npy', {})'''.format(str3, str3))\n",
    "\n",
    "#train_s = [i[0]+['<sent>']+i[1] for i in train_src]\n",
    "#val_s = [i[0]+['<sent>']+i[1] for i in val_src]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "643c6704-9de7-453d-a14e-37b6867e4e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['In',\n",
       "  'subsection',\n",
       "  '(5)',\n",
       "  ',',\n",
       "  'after',\n",
       "  '“review',\n",
       "  'of”',\n",
       "  'insert',\n",
       "  '“the',\n",
       "  'Secretary',\n",
       "  'of',\n",
       "  'State’s',\n",
       "  'powers',\n",
       "  'under”.',\n",
       "  '<sent>',\n",
       "  'The',\n",
       "  'Secretary',\n",
       "  'of',\n",
       "  'State',\n",
       "  'must',\n",
       "  'carry',\n",
       "  'out',\n",
       "  'a',\n",
       "  'review',\n",
       "  'of',\n",
       "  'sections',\n",
       "  '45',\n",
       "  'and',\n",
       "  '46',\n",
       "  'and',\n",
       "  'the',\n",
       "  'preceding',\n",
       "  'provisions',\n",
       "  'of',\n",
       "  'this',\n",
       "  'section',\n",
       "  'as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'reasonably',\n",
       "  'practicable',\n",
       "  'after',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'period',\n",
       "  'of',\n",
       "  '5',\n",
       "  'years',\n",
       "  'beginning',\n",
       "  'with',\n",
       "  'the',\n",
       "  'day',\n",
       "  'on',\n",
       "  'which',\n",
       "  'they',\n",
       "  'come',\n",
       "  'into',\n",
       "  'force.'],\n",
       " array([list(['The', 'Secretary', 'of', 'State', 'must', 'carry', 'out', 'a', 'review', 'of', 'the', 'Secretary', 'of', \"State's\", 'powers', 'under', 'sections', '45', 'and', '46', 'and', 'the', 'preceding', 'provisions', 'of', 'this', 'section', 'as', 'soon', 'as', 'reasonably', 'practicable', 'after', 'the', 'end', 'of', 'the', 'period', 'of', '5', 'years', 'beginning', 'with', 'the', 'day', 'on', 'which', 'they', 'come', 'into', 'force.']),\n",
       "        list([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_s[10], val_tar[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615ec813-6b97-4b7a-942a-18e027232188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPECIAL_TOKEN = {'additional_special_tokens': ['<change>', '<sent>', '<type>']}\n",
    "SPECIAL_TOKEN = {'additional_special_tokens': ['<sent>']}\n",
    "tokenizer.add_special_tokens(SPECIAL_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10797379-abb8-410a-b33c-12b1670e0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_bio(seq, id2label):\n",
    "        \"\"\"Gets entities from sequence.\n",
    "        note: BIO\n",
    "        Args:\n",
    "            seq (list): sequence of labels.\n",
    "        Returns:\n",
    "            list: list of (chunk_type, chunk_start, chunk_end).\n",
    "        Example:\n",
    "            seq = ['B-PER', 'I-PER', 'O', 'B-LOC']\n",
    "            get_entity_bio(seq)\n",
    "            #output\n",
    "            [['PER', 0,1], ['LOC', 3, 3]]\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        chunk = [-1, -1, -1]\n",
    "        for indx, tag in enumerate(seq):\n",
    "            if not isinstance(tag, str):\n",
    "                tag = id2label[tag]\n",
    "            if tag.startswith(\"B-\"):\n",
    "                if chunk[2] != -1:\n",
    "                    chunks.append(chunk)\n",
    "                chunk = [-1, -1, -1]\n",
    "                chunk[1] = indx\n",
    "                chunk[0] = '-'.join(tag.split('-')[1:])\n",
    "                chunk[2] = indx\n",
    "                if indx == len(seq) - 1:\n",
    "                    chunks.append(chunk)\n",
    "            elif tag.startswith('I-') and chunk[1] != -1:\n",
    "                _type = '-'.join(tag.split('-')[1:])\n",
    "                if _type == chunk[0]:\n",
    "                    chunk[2] = indx\n",
    "\n",
    "                if indx == len(seq) - 1:\n",
    "                    chunks.append(chunk)\n",
    "            else:\n",
    "                if chunk[2] != -1:\n",
    "                    chunks.append(chunk)\n",
    "                chunk = [-1, -1, -1]\n",
    "        return chunks\n",
    "    \n",
    "def preprocess_function(src, tar, ner_label, mask):\n",
    "    short_label_list = ['O', 'substitute', 'before-insertions', 'after-insertions', 'revocation']\n",
    "    label2id = {label: i for i, label in enumerate(short_label_list)}\n",
    "    attention_mask = []\n",
    "    start_ids_labels = []\n",
    "    end_ids_labels = []\n",
    "    '''\n",
    "    model_inputs = tokenizer(src['0'],\n",
    "                             src['1'],\n",
    "                             is_split_into_words=True,\n",
    "                             max_length=max_input_length, \n",
    "                             truncation='only_second',\n",
    "                             padding=True,)\n",
    "    '''\n",
    "    model_inputs = tokenizer(src['0'],\n",
    "                             src['1'],\n",
    "                             is_split_into_words=True,\n",
    "                             max_length=max_input_length, \n",
    "                             truncation='only_second',\n",
    "                             padding=True,)\n",
    "    for i in range(len(mask)):\n",
    "        \n",
    "        length = len(src['0'][i])\n",
    "        word_ids = model_inputs.word_ids(i)\n",
    "        cnt = 0\n",
    "        for j, ids in enumerate(word_ids):\n",
    "            if word_ids[j] is None:\n",
    "                cnt += 1\n",
    "                continue\n",
    "            if cnt == 3:\n",
    "                word_ids[j] += length \n",
    "        word_idx_dict = {}\n",
    "        for n in range(len(word_ids)):\n",
    "            if word_ids[n] in word_idx_dict or word_ids[n] is None:\n",
    "                continue\n",
    "            word_idx_dict[word_ids[n]] = n\n",
    "        \n",
    "        m = mask[i]\n",
    "        token_mask = [0] * len(word_ids)\n",
    "        #print(i, word_ids, word_idx_dict, m, len(word_ids), len(m))\n",
    "        for j in range(len(word_ids)):\n",
    "            if word_ids[j] is None:\n",
    "                continue\n",
    "            else:\n",
    "                token_mask[j] = m[word_ids[j]]\n",
    "        #ner_labels.append()\n",
    "        attention_mask.append(token_mask)\n",
    "            \n",
    "        start_ids = [0] * len(word_ids)\n",
    "        end_ids = [0] * len(word_ids)\n",
    "        n = 0\n",
    "        subjects = get_entity_bio(ner_label[i], label_dict_rev)\n",
    "        for subject in subjects:\n",
    "            label = subject[0]\n",
    "            start = subject[1]\n",
    "            end = subject[2]\n",
    "            #print(start, end)\n",
    "            if start in word_idx_dict and end in word_idx_dict:\n",
    "                start_ids[word_idx_dict[start]] = label2id[label]\n",
    "                end_ids[word_idx_dict[end]] = label2id[label]\n",
    "                n+=3\n",
    "        start_ids_labels.append(start_ids)\n",
    "        end_ids_labels.append(end_ids)\n",
    "        \n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(tar, \n",
    "                           is_split_into_words=True, \n",
    "                           max_length=max_target_length, \n",
    "                           truncation=True)\n",
    "    #model_inputs['attention_mask'] = attention_mask\n",
    "    model_inputs['start_positions'] = start_ids_labels\n",
    "    model_inputs['end_positions'] = end_ids_labels\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "train_encodings = preprocess_function(train_src_dict, train_tar_dict['0'], train_tar_dict['2'], train_tar_dict['1'])\n",
    "val_encodings = preprocess_function(val_src_dict, val_tar_dict['0'], val_tar_dict['2'], val_tar_dict['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0849e843-c11f-4437-832b-fb8f09f796a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=256, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_encodings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c69669-76b4-42e3-b551-9c6ed6340c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Seq2seqdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, type_id_lists):\n",
    "        self.encodings = encodings\n",
    "        self.type_id_lists = type_id_lists\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        #item['type_ids'] = torch.tensor(self.type_id_lists[idx])\n",
    "        item['labels'] = torch.tensor(self.encodings['labels'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['labels'])\n",
    "\n",
    "train_dataset = Seq2seqdataset(train_encodings, train_tar_dict['1'])\n",
    "val_dataset = Seq2seqdataset(val_encodings, val_tar_dict['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78eb9a42-a3b2-447b-b607-7282b015cae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,    96, 45845,    36,   134,    43,  2156,    13,    44,    48,\n",
       "         45580,    17,    46, 10268,    44,    48,   771, 44870,  3389,  1621,\n",
       "            50,     5,   496,  3389,    13,  5295,  1463,    17,    46,     4,\n",
       "             2,     2,   660,   645,   223,  2810,   971,  1640,   176,    43,\n",
       "           189,    45, 43388,     5,  3389,    31, 22557,   155,     4,     2,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'start_positions': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'end_positions': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([    0,   660,   645,   223,  2810,   971,  1640,   176,    43,   189,\n",
       "            45, 43388,     5, 12093,  3389,  1621,    50,     5,   496,  3389,\n",
       "            13,  5295,  1463,    31, 22557,   155,     4,     2])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73675d63-9cb1-416f-9427-de3f3f425519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartNerJointModel were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['dense1.bias', 'dense1.weight', 'dense2.bias', 'dense2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import BartConfig\n",
    "from models import BartNerJointModel\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "num_labels = len(short_label_list)\n",
    "config = BartConfig.from_pretrained(model_checkpoint,num_labels=num_labels)\n",
    "config.loss_type = 'ce'\n",
    "model = BartNerJointModel.from_pretrained(model_checkpoint, config=config)\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59954c8f-bf9e-4155-928b-3beef7e8e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "batch_size = 8\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy ='epoch',\n",
    "    num_train_epochs=5,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    generation_num_beams=3,\n",
    "    generation_max_length=512,\n",
    "    #fp16=True,\n",
    "    push_to_hub=False,\n",
    "    no_cuda=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3716b92-af1b-46f9-9084-ed1abc6c4c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7793\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4876' max='4875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4875/4875 23:08, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Strict-match-ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>0.121602</td>\n",
       "      <td>95.859900</td>\n",
       "      <td>94.557500</td>\n",
       "      <td>95.652300</td>\n",
       "      <td>95.622500</td>\n",
       "      <td>45.295000</td>\n",
       "      <td>0.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.104435</td>\n",
       "      <td>95.976000</td>\n",
       "      <td>94.782900</td>\n",
       "      <td>95.760300</td>\n",
       "      <td>95.757400</td>\n",
       "      <td>44.989200</td>\n",
       "      <td>0.567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.099790</td>\n",
       "      <td>96.105000</td>\n",
       "      <td>94.875500</td>\n",
       "      <td>95.858700</td>\n",
       "      <td>95.860400</td>\n",
       "      <td>45.532100</td>\n",
       "      <td>0.571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.096284</td>\n",
       "      <td>95.922800</td>\n",
       "      <td>94.759300</td>\n",
       "      <td>95.751400</td>\n",
       "      <td>95.742600</td>\n",
       "      <td>44.654700</td>\n",
       "      <td>0.578800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/244 02:44 < 01:04, 1.06 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1949\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bart-base-finetuned-xsum/checkpoint-975\n",
      "Configuration saved in bart-base-finetuned-xsum/checkpoint-975/config.json\n",
      "Model weights saved in bart-base-finetuned-xsum/checkpoint-975/pytorch_model.bin\n",
      "tokenizer config file saved in bart-base-finetuned-xsum/checkpoint-975/tokenizer_config.json\n",
      "Special tokens file saved in bart-base-finetuned-xsum/checkpoint-975/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1949\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bart-base-finetuned-xsum/checkpoint-1950\n",
      "Configuration saved in bart-base-finetuned-xsum/checkpoint-1950/config.json\n",
      "Model weights saved in bart-base-finetuned-xsum/checkpoint-1950/pytorch_model.bin\n",
      "tokenizer config file saved in bart-base-finetuned-xsum/checkpoint-1950/tokenizer_config.json\n",
      "Special tokens file saved in bart-base-finetuned-xsum/checkpoint-1950/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1949\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bart-base-finetuned-xsum/checkpoint-2925\n",
      "Configuration saved in bart-base-finetuned-xsum/checkpoint-2925/config.json\n",
      "Model weights saved in bart-base-finetuned-xsum/checkpoint-2925/pytorch_model.bin\n",
      "tokenizer config file saved in bart-base-finetuned-xsum/checkpoint-2925/tokenizer_config.json\n",
      "Special tokens file saved in bart-base-finetuned-xsum/checkpoint-2925/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1949\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to bart-base-finetuned-xsum/checkpoint-3900\n",
      "Configuration saved in bart-base-finetuned-xsum/checkpoint-3900/config.json\n",
      "Model weights saved in bart-base-finetuned-xsum/checkpoint-3900/pytorch_model.bin\n",
      "tokenizer config file saved in bart-base-finetuned-xsum/checkpoint-3900/tokenizer_config.json\n",
      "Special tokens file saved in bart-base-finetuned-xsum/checkpoint-3900/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1949\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7c9e8c041312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, max_length, num_beams)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_max_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_num_beams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     def predict(\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m         )\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m             \u001b[0;31m# Update containers on host\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         )\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# in case the batch is shorter than max length, the output should be padded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m             )\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m             )\n\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/legislation/end2end/huggingface_summary/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, start_positions, end_positions, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m         )\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m                 )\n\u001b[1;32m   1070\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# Cross-Attention Block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miniconda3/envs/pytorch_1.9/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(len(decoded_preds)):\n",
    "        if decoded_preds[i] == decoded_labels[i]:\n",
    "            cnt += 1\n",
    "    ratio = cnt/len(decoded_preds)\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result[\"Strict-match-ratio\"] = ratio\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f70fd6-adaa-4ebf-b930-d8d9e105ce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 21,  3],\n",
       "        [ 2, 32,  3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([1,21,3])\n",
    "t2 = torch.tensor([2,32,3])\n",
    "t3 = torch.stack((t1, t2, t2, t2))\n",
    "t4 = (t1, t2)\n",
    "torch.stack(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25c14d2b-40a2-4a75-b152-ef8414f628c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import Seq2SeqLMOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5f076-29e1-4fb9-9f7f-068ccb8dfaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForSeq2SeqLM.from_pretrained('./bart-base-finetuned-xsum/checkpoint-7794')\n",
    "#model.to('cuda')\n",
    "#model.eval()\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer)\n",
    "\n",
    "def predict_report(trainer, dataset):\n",
    "    \n",
    "    predictions, label_ids, metrics = trainer.predict(dataset, num_beams=3, max_length=512)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    print(len(decoded_preds[0]), len(decoded_preds[1]))\n",
    "    print(len(decoded_preds))\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(200):\n",
    "        if decoded_preds[i] == decoded_labels[i]:\n",
    "            cnt += 1\n",
    "            print('Same:', decoded_preds[i])\n",
    "        else:\n",
    "            print('Diff:', decoded_preds[i])\n",
    "            print('.......')\n",
    "            print(decoded_labels[i])\n",
    "        print('----------------------------------')\n",
    "    ratio = cnt/len(decoded_preds)\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}, {'ratio':ratio}\n",
    "\n",
    "print(predict_report(trainer, val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6cc1635-4c89-40e1-95e8-2b15ccd72df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'member', 'of', 'a', 'police', 'force', 'seconded', 'to', 'the', 'National', 'Crime', 'Agency', 'to', 'serve', 'as', 'a', 'National', 'Crime', 'Agency', 'officer', 'is', 'to', 'be', 'treated', 'as', 'employed', 'by', 'that', 'Agency.'] ['substitute', '“seconded', 'to', 'the', 'National', 'Crime', 'Agency', 'to', 'serve', 'as', 'a', 'National', 'Crime', 'Agency', 'officer', 'is', 'to', 'be', 'treated”.', '<sent>', 'a', 'member', 'of', 'a', 'police', 'force', 'as', 'employed', 'by', 'that', 'Agency.']\n"
     ]
    }
   ],
   "source": [
    "a = val_s[10] \n",
    "b = val_tar[10]\n",
    "c = [a[i] for i in range(len(a)) if b[1][i]==1]\n",
    "print(b[0], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "204cb653-91c4-4e0d-bf6f-3062229345bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'the', 'words', '“Supreme', 'Court', 'Act', '1981”,', 'substitute', '“', ',', 'that', 'the', 'decision”', '<sent>', 'after', 'paragraph', '(e)', 'of', '<change>', '1981', 'insert—“(ea)', 'proceedings', 'under', 'section', '79', 'of', 'the', 'Childcare', 'Act', '2006;”']\n",
      "after paragraph (e) of , that the decision 1981 insert —“(ea) proceedings under section 79 of the Childcare Act 2006;” \n",
      " after paragraph (e) of , that the decision insert—“(ea) proceedings under section 79 of the Childcare Act 2006;”\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.9375, 'p': 0.8333333333333334, 'f': 0.8823529361937716},\n",
       "  'rouge-2': {'r': 0.8823529411764706,\n",
       "   'p': 0.7894736842105263,\n",
       "   'f': 0.8333333283487654},\n",
       "  'rouge-l': {'r': 0.9375, 'p': 0.8333333333333334, 'f': 0.8823529361937716}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "src = 'for the words “Supreme Court Act 1981”, substitute “ , that the decision”'\n",
    "tar_before = 'after paragraph (e) of <change> 1981 insert—“(ea) proceedings under section 79 of the Childcare Act 2006;”'\n",
    "tar_after = 'after paragraph (e) of , that the decision insert—“(ea) proceedings under section 79 of the Childcare Act 2006;”'\n",
    "'''\n",
    "src = 'for the words from “a condition of a direction” to “specified by him”, substitute “fuck you”'\n",
    "tar_before ='The Secretary of State may make it <change>.'\n",
    "tar_after = 'The Secretary of State may make it fuck you.'\n",
    "\n",
    "src = 'in paragraph (2), for “23(3) or 24(3)” substitute “23(1)(de)(ii), (1)(df)(ii), (3), 24(1)(ce)(ii), (1)(cf)(ii) or (3)”.'\n",
    "tar_before = 'Where a person has his appointment revoked or if an approval given in respect of him under regulation <change> is withdrawn, that person shall immediately return to the Secretary of State all forms of pass certificates supplied to him under regulations 47(8) and 48(3) which he still holds.'\n",
    "tar_after = 'Where a person has his appointment revoked or if an approval given in respect of him under regulation 23(1)(de)(ii), (1)(df)(ii), (3), 24(1)(ce)(ii), (1)(cf)(ii) or (3) is withdrawn, that person shall immediately return to the Secretary of State all forms of pass certificates supplied to him under regulations 47(8) and 48(3) which he still holds.'\n",
    "\n",
    "src = 'In section 86 of the Act (exempt offers to the public) , in subsections (1A)(c) and (1B)(a) , after “the FCA” insert “or the competent authority of another EEA State”.'\n",
    "tar_before = 'a prospectus is available for the securities which has been approved by the FCA <change> and meets either of the conditions in subsection (1B) ; and'\n",
    "tar_after = 'a prospectus is available for the securities which has been approved by the FCA or the competent authority of another EEA State and meets either of the conditions in subsection (1B) ; and'\n",
    "\n",
    "src = 'In subsection (5EA), omit \"and the reference to the Registrar General in subsection (5C) accordingly has effect as a reference to the Secretary of State\".'\n",
    "tar_before = 'If a proposed marriage is referred to the Secretary of State under section 28H— (a)any application under subsection (5A) is to be made to the Secretary of State; and (b)the power conferred by subsection (5A) is exercisable by the Secretary of State <change>.'\n",
    "tar_after = 'If a proposed marriage is referred to the Secretary of State under section 28H— (a)any application under subsection (5A) is to be made to the Secretary of State; and (b)the power conferred by subsection (5A) is exercisable by the Secretary of State ... .'\n",
    "\n",
    "src = 'for \"the superintendent registrar\" (in the first place it appears) substitute \"any superintendent registrar\";'\n",
    "tar_before = 'The provisions of section 29 of the principal Act (caveat against issue of certificate) shall apply to the issue of a licence by the Registrar General with the modification that a caveat may be entered with either <change> or the Registrar General and in either case it shall be for the Registrar General to examine into the matter of the caveat and to decide whether or not the licence should be granted and his decision shall be final, and with a further modification that the references to the superintendent registrar in that section shall refer to the superintendent registrar of the registration district in which the marriage is intended to be solemnised.'\n",
    "tar_after = 'The provisions of section 29 of the principal Act (caveat against issue of certificate) shall apply to the issue of a licence by the Registrar General with the modification that a caveat may be entered with either any superintendent registrar or the Registrar General and in either case it shall be for the Registrar General to examine into the matter of the caveat and to decide whether or not the licence should be granted and his decision shall be final, and with a further modification that the references to the superintendent registrar in that section shall refer to the superintendent registrar of the registration district in which the marriage is intended to be solemnised.'\n",
    "'''\n",
    "set_type = {'substitute', 'insert', 'omit'}\n",
    "src_list = src.split(' ')\n",
    "src = []\n",
    "'''\n",
    "flag = 0\n",
    "for i in src_list:\n",
    "    if flag == 1:\n",
    "        src.append(i)\n",
    "    if i in set_type:\n",
    "        src.append(i)\n",
    "        src.append('<type>') \n",
    "        flag = 1\n",
    "'''\n",
    "for i in src_list:\n",
    "    src.append(i)\n",
    "    #if i in set_type:\n",
    "        #src.append('<type>') \n",
    "        \n",
    "input_list = src + ['<sent>'] + tar_before.split(' ')\n",
    "print(input_list)\n",
    "test_encodings = tokenizer(input_list, is_split_into_words=True,\n",
    "                           max_length=max_input_length,\n",
    "                           return_offsets_mapping=True, truncation=True)\n",
    "model.eval()\n",
    "summary_ids = model.generate(torch.tensor([test_encodings[\"input_ids\"]]).cuda(), num_beams=3, max_length=512, early_stopping=True)\n",
    "hypothesis = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "\n",
    "hypothesis = hypothesis[0].strip()\n",
    "reference = tar_after\n",
    "\n",
    "print(hypothesis, '\\n', reference)\n",
    "print(hypothesis==reference)\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hypothesis, reference)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8feb210-48b8-43f6-b109-604a463f4d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 100.0, 'rouge2': 100.0, 'rougeL': 100.0, 'rougeLsum': 100.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = metric.compute(predictions=['a a a'], references=['a a a'], use_stemmer=True)\n",
    "result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91770cb-6cb3-48ae-9e87-225a7aa15817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from models.seq2seq import *\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained('./weights/annotation_gen_BART')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('./weights/annotation_gen_BART')\n",
    "#\n",
    "# ARTICLE_TO_SUMMARIZE = \"In Article 8 (civil-military coordination), in each of paragraphs 1 to 3 for “Member States” substitute “The Secretary of State”.\"\n",
    "# inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n",
    "#\n",
    "# # Generate Summary\n",
    "# summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=30, early_stopping=True)\n",
    "# [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained('./weights/annotation_gen_BART/')\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        return self.model.generate(input_ids, num_beams=4, max_length=30, early_stopping=True)\n",
    "\n",
    "\n",
    "def export_seq2seq_onnx_representation(model_path='./bart-base-finetuned-xsum/checkpoint-1220', save_path='./'):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    encoder = model.model.encoder\n",
    "    decoder = model.model.decoder\n",
    "    lm_head = model.lm_head\n",
    "\n",
    "    decoder_with_lm_head = CombinedDecoder(decoder, lm_head, model.config)\n",
    "    simplified_encoder = SimplifiedT5Encoder(encoder)\n",
    "    # Example sequence\n",
    "    input_ids = torch.tensor([[42] * 10])\n",
    "\n",
    "    # Exports to ONNX\n",
    "    _ = torch.onnx.export(\n",
    "        decoder_with_lm_head.eval(),\n",
    "        (input_ids, simplified_encoder(input_ids)),\n",
    "        f\"{save_path}/decoder.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=12,\n",
    "        input_names=['input_ids', 'encoder_hidden_states'],\n",
    "        output_names=['hidden_states'],\n",
    "        dynamic_axes={\n",
    "            'input_ids': {0: 'batch', 1: 'sequence'},\n",
    "            'encoder_hidden_states': {0: 'batch', 1: 'sequence'},\n",
    "            'hidden_states': {0: 'batch', 1: 'sequence'},\n",
    "        })\n",
    "\n",
    "    _ = torch.onnx._export(\n",
    "        simplified_encoder.eval(),\n",
    "        input_ids,\n",
    "        f\"{save_path}/encoder.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=12,\n",
    "        input_names=['input_ids'],\n",
    "        output_names=['hidden_states'],\n",
    "        dynamic_axes={\n",
    "            'input_ids': {0: 'batch', 1: 'sequence'},\n",
    "            'hidden_states': {0: 'batch', 1: 'sequence'},\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# import onnxruntime\n",
    "# ort_session = onnxruntime.InferenceSession(\"./weights/bart_onnx/bart.onnx\")\n",
    "#\n",
    "# def to_numpy(tensor):\n",
    "#     return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "#\n",
    "# # compute ONNX Runtime output prediction\n",
    "# x = torch.randint(high=100, size=(1, 256))\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n",
    "if __name__ == '__main__':\n",
    "    export_seq2seq_onnx_representation()\n",
    "    print(\"Model exported at \", './weights/bart_onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a130a11-0c80-4944-a57f-009e41c730fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some standard imports\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "\n",
    "# Super Resolution model definition in PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "\n",
    "# Create the super-resolution model by using the above model definition.\n",
    "torch_model = SuperResolutionNet(upscale_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04e473b3-c0ae-4f99-8479-9c42156ddfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth\" to /root/.cache/torch/hub/checkpoints/superres_epoch100-44c6958e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674bcd3d4d024ba7a8852953f0ff0d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/234k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuperResolutionNet(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pixel_shuffle): PixelShuffle(upscale_factor=3)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model weights\n",
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "batch_size = 1    # just a random number\n",
    "\n",
    "# Initialize model with the pretrained weights\n",
    "map_location = lambda storage, loc: storage\n",
    "if torch.cuda.is_available():\n",
    "    map_location = None\n",
    "torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))\n",
    "\n",
    "# set the model to inference mode\n",
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63ae1dca-bc1d-46c8-9097-74baddaece58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "x = torch.randn(batch_size, 1, 224, 224, requires_grad=True)\n",
    "torch_out = torch_model(x)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(torch_model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36218b19-9a3f-4c2e-bc31-edfb46628d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"super_resolution.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "825028d1-ece7-4165-84bc-71a51e370e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657350fc-5a7f-4d01-ac13-46b1493bc4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1.9",
   "language": "python",
   "name": "pytorch_1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
